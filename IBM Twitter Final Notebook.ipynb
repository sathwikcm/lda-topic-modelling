{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'XXXXXXXXX'\n",
    "consumer_secret = 'XXXXXXXXX'\n",
    "access_token = 'XXXXXXXXX'\n",
    "access_token_secret= 'XXXXXXXXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': '2019-04-18', 'end': '2019-04-19'}\n",
      "{'start': '2019-04-19', 'end': '2019-04-20'}\n",
      "{'start': '2019-04-20', 'end': '2019-04-21'}\n",
      "{'start': '2019-04-21', 'end': '2019-04-22'}\n",
      "{'start': '2019-04-22', 'end': '2019-04-23'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tweets = []\n",
    "dates =[{\"start\" : \"2019-04-18\", \"end\":\"2019-04-19\"},\n",
    "        {\"start\" : \"2019-04-19\", \"end\":\"2019-04-20\"},\n",
    "        {\"start\" : \"2019-04-20\", \"end\":\"2019-04-21\"},\n",
    "        {\"start\" : \"2019-04-21\", \"end\":\"2019-04-22\"},\n",
    "        {\"start\" : \"2019-04-22\", \"end\":\"2019-04-23\"}]\n",
    "\n",
    "for each_date in dates:\n",
    "    print(each_date)\n",
    "    for status in tweepy.Cursor(api.search,q=\"#ibm\",\n",
    "                                since=each_date[\"start\"], until=each_date[\"end\"],tweet_mode='extended',\n",
    "                               result_type='recent', include_entities=True, monitor_rate_limit=True, \n",
    "                               wait_on_rate_limit=True,  lang=\"en\").items():\n",
    "        tweets.append(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1842"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_text = [i.full_text for i in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“Equality is not about fixing women, it’s about fixing everything else!” -Larry Fink #womensbondclub #blackrock #ibm https://t.co/62v8gt8sAN',\n",
       " 'RT @cloudbetweter: Great blog by @andy_gower from @IBMcloud categorized as #Infrastructure (strange). Leading to an #IBM commissioned study…',\n",
       " 'RT @TDASUK_FrankR: Arm Yourself with @IBMCloud Strategy - The world is changing rapidly. Invest in your talent and skills. Start here to la…',\n",
       " 'RT @unixbhaskar: Okay, showing off :) my #fedora system and this fellow is rolling over from build to build.\\n\\n@nixcraft @harishpillay @kern…']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_text[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Saved Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['“Equality is not about fixing women, it’s about fixing everything else!” -Larry Fink #womensbondclub #blackrock #ibm https://t.co/62v8gt8sAN',\n",
       " 'RT @cloudbetweter: Great blog by @andy_gower from @IBMcloud categorized as #Infrastructure (strange). Leading to an #IBM commissioned study…',\n",
       " 'RT @TDASUK_FrankR: Arm Yourself with @IBMCloud Strategy - The world is changing rapidly. Invest in your talent and skills. Start here to la…',\n",
       " 'RT @unixbhaskar: Okay, showing off :) my #fedora system and this fellow is rolling over from build to build.\\n\\n@nixcraft @harishpillay @kern…']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('tweets_file.txt','r') as f:\n",
    "    tweets_from_file = f.read()\n",
    "    \n",
    "listof_tweets_from_file = tweets_from_file.split('|||')\n",
    "listof_tweets_from_file = listof_tweets_from_file[:-1]\n",
    "print(len(listof_tweets_from_file))\n",
    "listof_tweets_from_file[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#source: https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = []\n",
    "for i in listof_tweets_from_file:\n",
    "    processed_docs.append(preprocess(i))\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA on Bag of Words Approach ( Term Frequencies or Count Vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.022*\"cybersecur\" + 0.019*\"learn\" + 0.019*\"secur\" + 0.019*\"need\" + 0.018*\"build\" + 0.018*\"bigdata\" + 0.017*\"busi\" + 0.017*\"trust\" + 0.016*\"solut\" + 0.016*\"help\"\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.046*\"blockchain\" + 0.032*\"encrypt\" + 0.019*\"time\" + 0.018*\"amazon\" + 0.017*\"ibmz\" + 0.017*\"thomas_harr\" + 0.017*\"turn\" + 0.016*\"cybersecur\" + 0.016*\"cyberresili\" + 0.015*\"boost\"\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.118*\"ibmsystem\" + 0.031*\"socialcto\" + 0.025*\"proudibm\" + 0.020*\"ibmz\" + 0.017*\"berlin\" + 0.017*\"free\" + 0.017*\"opportun\" + 0.016*\"brand\" + 0.016*\"miss\" + 0.016*\"present\"\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.028*\"world\" + 0.022*\"secur\" + 0.022*\"watson\" + 0.021*\"ibmcloud\" + 0.021*\"join\" + 0.015*\"employe\" + 0.014*\"blockchain\" + 0.014*\"manag\" + 0.014*\"hide\" + 0.013*\"rhsummit\"\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.032*\"week\" + 0.031*\"client\" + 0.030*\"help\" + 0.025*\"develop\" + 0.024*\"announc\" + 0.022*\"learn\" + 0.019*\"cloud\" + 0.018*\"global\" + 0.017*\"innov\" + 0.017*\"thrill\"\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.034*\"blockchain\" + 0.034*\"join\" + 0.029*\"cloud\" + 0.027*\"partner\" + 0.022*\"chain\" + 0.022*\"suppli\" + 0.021*\"help\" + 0.019*\"summit\" + 0.018*\"platform\" + 0.018*\"infrastructur\"\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.063*\"berlin\" + 0.058*\"ibmsystem\" + 0.058*\"thinkatibm\" + 0.039*\"thomas_harr\" + 0.032*\"data\" + 0.024*\"ibmtechu\" + 0.024*\"proudibm\" + 0.022*\"socialcto\" + 0.019*\"meet\" + 0.018*\"think\"\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.043*\"blockchain\" + 0.030*\"watson\" + 0.018*\"team\" + 0.018*\"certif\" + 0.017*\"busi\" + 0.016*\"solut\" + 0.016*\"data\" + 0.015*\"demand\" + 0.015*\"cognit\" + 0.015*\"profession\"\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.047*\"thomas_harr\" + 0.040*\"nodexl\" + 0.034*\"learn\" + 0.034*\"topcybernew\" + 0.031*\"cloud\" + 0.023*\"spectrum\" + 0.022*\"cyber\" + 0.022*\"come\" + 0.019*\"virtual\" + 0.019*\"ibmstorag\"\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.045*\"blockchain\" + 0.029*\"chain\" + 0.028*\"suppli\" + 0.025*\"market\" + 0.024*\"work\" + 0.022*\"watson\" + 0.019*\"data\" + 0.018*\"enterpris\" + 0.017*\"analyt\" + 0.015*\"track\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}\\n'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Based on the keywords, we can identify the following topics:\n",
    "     \n",
    "    Topic: CYBERSECURITY\n",
    "    Words:,cybersecur,learn,secur,need,build,bigdata,busi,trust,solut,help\n",
    "\n",
    "    Topic: BLOCKCHAIN SECURITY\n",
    "    Words:,blockchain,encrypt,time,amazon,ibmz,thomas_harr,turn,cybersecur,cyberresili,boost\n",
    "\n",
    "    Topic: IBM BRAND\n",
    "    Words:,ibmsystem,socialcto,proudibm,ibmz,berlin,free,opportun,brand,miss,present\n",
    "\n",
    "    Topic: WATSON CLOUD\n",
    "    Words:,world,secur,watson,ibmcloud,join,employe,blockchain,manag,hide,rhsummit\n",
    "\n",
    "    Topic: CLIENT RELATIONS\n",
    "    Words:,week,client,help,develop,announc,learn,cloud,global,innov,thrill\n",
    "\n",
    "    Topic: BLOCKCHAIN CLOUD\n",
    "    Words:,blockchain,join,cloud,partner,chain,suppli,help,summit,platform,infrastructur\n",
    "\n",
    "    Topic: THINK AT BERLIN\n",
    "    Words:,berlin,ibmsystem,thinkatibm,thomas_harr,data,ibmtechu,proudibm,socialcto,meet,think\n",
    "\n",
    "    Topic: BLOCKCHAIN WATSON TEAM\n",
    "    Words:,blockchain,watson,team,certif,busi,solut,data,demand,cognit,profession\n",
    "\n",
    "    Topic: -- \n",
    "    Words:,thomas_harr,nodexl,learn,topcybernew,cloud,spectrum,cyber,come,virtual,ibmstorag\n",
    "\n",
    "    Topic: BLOCKCHAIN MARKET\n",
    "    Words:,blockchain,chain,suppli,market,work,watson,data,enterpris,analyt,track\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA on TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Word: 0.022*\"secur\" + 0.016*\"cybersecur\" + 0.016*\"today\" + 0.016*\"world\" + 0.014*\"news\" + 0.013*\"iotexchang\" + 0.013*\"watson\" + 0.013*\"work\" + 0.013*\"microsoft\" + 0.012*\"servic\"\n",
      "\n",
      "Topic: 1 \n",
      "Word: 0.031*\"berlin\" + 0.030*\"topcybernew\" + 0.029*\"chidambara\" + 0.028*\"hide\" + 0.025*\"nodexl\" + 0.024*\"thinkatibm\" + 0.022*\"thomas_harr\" + 0.020*\"summit\" + 0.019*\"infrastructur\" + 0.018*\"ibmtechu\"\n",
      "\n",
      "Topic: 2 \n",
      "Word: 0.021*\"blockchain\" + 0.018*\"data\" + 0.015*\"want\" + 0.015*\"power\" + 0.015*\"client\" + 0.014*\"network\" + 0.014*\"announc\" + 0.014*\"video\" + 0.012*\"cloud\" + 0.012*\"prior\"\n",
      "\n",
      "Topic: 3 \n",
      "Word: 0.033*\"ibmsystem\" + 0.024*\"proudibm\" + 0.018*\"experi\" + 0.017*\"socialcto\" + 0.016*\"turn\" + 0.014*\"chevron\" + 0.014*\"applic\" + 0.014*\"netflix\" + 0.013*\"generalmotor\" + 0.013*\"amazon\"\n",
      "\n",
      "Topic: 4 \n",
      "Word: 0.041*\"blockchain\" + 0.028*\"volkswagen\" + 0.025*\"chain\" + 0.025*\"suppli\" + 0.020*\"build\" + 0.017*\"great\" + 0.016*\"univers\" + 0.016*\"week\" + 0.016*\"skill\" + 0.015*\"miner\"\n",
      "\n",
      "Topic: 5 \n",
      "Word: 0.026*\"manag\" + 0.026*\"data\" + 0.022*\"team\" + 0.019*\"talk\" + 0.018*\"certif\" + 0.018*\"check\" + 0.017*\"note\" + 0.017*\"best\" + 0.016*\"solut\" + 0.016*\"avail\"\n",
      "\n",
      "Topic: 6 \n",
      "Word: 0.028*\"ibmsystem\" + 0.027*\"cloud\" + 0.020*\"compani\" + 0.019*\"rhsummit\" + 0.018*\"blockchain\" + 0.017*\"miss\" + 0.016*\"brand\" + 0.016*\"work\" + 0.015*\"interact\" + 0.014*\"opportun\"\n",
      "\n",
      "Topic: 7 \n",
      "Word: 0.022*\"innov\" + 0.021*\"understand\" + 0.021*\"decad\" + 0.021*\"mikequindazzi\" + 0.020*\"loveibm\" + 0.019*\"help\" + 0.019*\"enterpris\" + 0.019*\"ilikeither\" + 0.018*\"advanc\" + 0.016*\"rometti\"\n",
      "\n",
      "Topic: 8 \n",
      "Word: 0.028*\"market\" + 0.024*\"encrypt\" + 0.022*\"thomas_harr\" + 0.021*\"futur\" + 0.021*\"share\" + 0.019*\"sale\" + 0.018*\"drug\" + 0.016*\"discoveri\" + 0.015*\"watson\" + 0.015*\"ibmsystem\"\n",
      "\n",
      "Topic: 9 \n",
      "Word: 0.031*\"watson\" + 0.025*\"game\" + 0.023*\"come\" + 0.022*\"ahead\" + 0.021*\"davidgokhshtein\" + 0.021*\"blockchaintech\" + 0.018*\"ibmsystem\" + 0.018*\"thinkatibm\" + 0.017*\"meet\" + 0.017*\"ibmstorag\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "\n",
    "\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWord: {}\\n'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Based on the keywords, we can identify the following topics:\n",
    "    \n",
    "    Topic 0: CYBER SECURITY\n",
    "    Word:,secur,cybersecur,today,world,news,iotexchang,watson,work,microsoft,servic,\n",
    "\n",
    "    Topic 1: THINK AT BERLIN\n",
    "    Word:,berlin,topcybernew,chidambara,hide,nodexl,thinkatibm,thomas_harr,summit,infrastructur,ibmtechu,\n",
    "\n",
    "    Topic 2: BLOCKCHAIN IN DATA AND NETWORKS\n",
    "    Word:,blockchain,data,want,power,client,network,announc,video,cloud,prior,\n",
    "\n",
    "    Topic 3: IBM SOCIAL\n",
    "    Word:,ibmsystem,proudibm,experi,socialcto,turn,chevron,applic,netflix,generalmotor,amazon,\n",
    "\n",
    "    Topic 4: BLOCKCHAIN IN SUPPLY CHAIN\n",
    "    Word:,blockchain,volkswagen,chain,suppli,build,great,univers,week,skill,miner,\n",
    "\n",
    "    Topic 5: DATA SOLUTIONS\n",
    "    Word:,manag,data,team,talk,certif,check,note,best,solut,avail,\n",
    "\n",
    "    Topic 6: IBM CLOUD\n",
    "    Word:,ibmsystem,cloud,compani,rhsummit,blockchain,miss,brand,work,interact,opportun,\n",
    "\n",
    "    Topic 7: INNOVATION AT IBM\n",
    "    Word:,innov,understand,decad,mikequindazzi,loveibm,help,enterpris,ilikeither,advanc,rometti,\n",
    "\n",
    "    Topic 8: MARKETS\n",
    "    Word:,market,encrypt,thomas_harr,futur,share,sale,drug,discoveri,watson,ibmsystem,\n",
    "\n",
    "    Topic 9: WATSON SYSTEMS\n",
    "    Word:,watson,game,come,ahead,davidgokhshtein,blockchaintech,ibmsystem,thinkatibm,meet,ibmstorag,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of an Unseen Text (Tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using LDA with TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBM signs banking hybrid cloud services deal with Boursorama\n"
     ]
    }
   ],
   "source": [
    "unseen_document = 'IBM signs banking hybrid cloud services deal with Boursorama'\n",
    "print(unseen_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7749557495117188\n",
      "Topic: 0.028*\"world\" + 0.022*\"secur\" + 0.022*\"watson\" + 0.021*\"ibmcloud\" + 0.021*\"join\"\n",
      "\n",
      "Score: 0.025011036545038223\n",
      "Topic: 0.047*\"thomas_harr\" + 0.040*\"nodexl\" + 0.034*\"learn\" + 0.034*\"topcybernew\" + 0.031*\"cloud\"\n",
      "\n",
      "Score: 0.025008708238601685\n",
      "Topic: 0.034*\"blockchain\" + 0.034*\"join\" + 0.029*\"cloud\" + 0.027*\"partner\" + 0.022*\"chain\"\n",
      "\n",
      "Score: 0.025006350129842758\n",
      "Topic: 0.022*\"cybersecur\" + 0.019*\"learn\" + 0.019*\"secur\" + 0.019*\"need\" + 0.018*\"build\"\n",
      "\n",
      "Score: 0.025006070733070374\n",
      "Topic: 0.032*\"week\" + 0.031*\"client\" + 0.030*\"help\" + 0.025*\"develop\" + 0.024*\"announc\"\n",
      "\n",
      "Score: 0.02500336430966854\n",
      "Topic: 0.043*\"blockchain\" + 0.030*\"watson\" + 0.018*\"team\" + 0.018*\"certif\" + 0.017*\"busi\"\n",
      "\n",
      "Score: 0.02500297874212265\n",
      "Topic: 0.063*\"berlin\" + 0.058*\"ibmsystem\" + 0.058*\"thinkatibm\" + 0.039*\"thomas_harr\" + 0.032*\"data\"\n",
      "\n",
      "Score: 0.025002775713801384\n",
      "Topic: 0.045*\"blockchain\" + 0.029*\"chain\" + 0.028*\"suppli\" + 0.025*\"market\" + 0.024*\"work\"\n",
      "\n",
      "Score: 0.025001661852002144\n",
      "Topic: 0.046*\"blockchain\" + 0.032*\"encrypt\" + 0.019*\"time\" + 0.018*\"amazon\" + 0.017*\"ibmz\"\n",
      "\n",
      "Score: 0.02500130981206894\n",
      "Topic: 0.118*\"ibmsystem\" + 0.031*\"socialcto\" + 0.025*\"proudibm\" + 0.020*\"ibmz\" + 0.017*\"berlin\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\nTopic: {}\\n\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using LDA with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.774971604347229\n",
      "Topic: 0.022*\"cybersecur\" + 0.019*\"learn\" + 0.019*\"secur\" + 0.019*\"need\" + 0.018*\"build\"\n",
      "\n",
      "Score: 0.025007976219058037\n",
      "Topic: 0.063*\"berlin\" + 0.058*\"ibmsystem\" + 0.058*\"thinkatibm\" + 0.039*\"thomas_harr\" + 0.032*\"data\"\n",
      "\n",
      "Score: 0.025005392730236053\n",
      "Topic: 0.043*\"blockchain\" + 0.030*\"watson\" + 0.018*\"team\" + 0.018*\"certif\" + 0.017*\"busi\"\n",
      "\n",
      "Score: 0.02500409632921219\n",
      "Topic: 0.118*\"ibmsystem\" + 0.031*\"socialcto\" + 0.025*\"proudibm\" + 0.020*\"ibmz\" + 0.017*\"berlin\"\n",
      "\n",
      "Score: 0.025002971291542053\n",
      "Topic: 0.045*\"blockchain\" + 0.029*\"chain\" + 0.028*\"suppli\" + 0.025*\"market\" + 0.024*\"work\"\n",
      "\n",
      "Score: 0.025002378970384598\n",
      "Topic: 0.034*\"blockchain\" + 0.034*\"join\" + 0.029*\"cloud\" + 0.027*\"partner\" + 0.022*\"chain\"\n",
      "\n",
      "Score: 0.025001803413033485\n",
      "Topic: 0.028*\"world\" + 0.022*\"secur\" + 0.022*\"watson\" + 0.021*\"ibmcloud\" + 0.021*\"join\"\n",
      "\n",
      "Score: 0.02500159852206707\n",
      "Topic: 0.046*\"blockchain\" + 0.032*\"encrypt\" + 0.019*\"time\" + 0.018*\"amazon\" + 0.017*\"ibmz\"\n",
      "\n",
      "Score: 0.025001170113682747\n",
      "Topic: 0.032*\"week\" + 0.031*\"client\" + 0.030*\"help\" + 0.025*\"develop\" + 0.024*\"announc\"\n",
      "\n",
      "Score: 0.02500104531645775\n",
      "Topic: 0.047*\"thomas_harr\" + 0.040*\"nodexl\" + 0.034*\"learn\" + 0.034*\"topcybernew\" + 0.031*\"cloud\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unseen_document = 'IBM signs banking hybrid cloud services deal with Boursorama'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "for index, score in sorted(lda_model_tfidf[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\nTopic: {}\\n\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
